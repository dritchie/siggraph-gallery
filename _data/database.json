{
   "adelta": {
      "Authors": [
         "Yuting Yang",
         "Connelly Barnes",
         "Andrew Adams",
         "Adam Finkelstein"
      ],
      "Caption": "Our compiler automatically differentiates discontinuous shader programs by extending reverse-mode automatic differentiation (AD) with novel differentiation rules. This allows efficient gradient-based optimization methods to optimize program parameters to best match a target (a), which is difficult to do by hand (b). Our pipeline takes as input a shader program initialized with configurations (c) that look very different from the reference, and converges to be nearly visually identical (d) within 15s. The compiler can also output the shader program with optimized parameters to GLSL, which allows programmers to interactively edit or animate the shader, such as adding texture (e). The optimized parameters can also be combined with other shader programs (e.g. b) to leverage their visual appearance while keeping the geometry close to the reference. For animation results please refer to our supplemental video.",
      "Figure #": "1",
      "Link to Paper": "https://www.cs.princeton.edu/~yutingy/docs/siggraph_2022.pdf",
      "Sub-field": "Other",
      "Title": "Aùõø: Autodiff for Discontinuous Programs \u2013 Applied to Shaders",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2022"
   },
   "antithetic": {
      "Authors": [
         "Cheng Zhang",
         "Zhao Dong",
         "Michael Doggett",
         "Shuang Zhao"
      ],
      "Caption": "Differentiable rendering of anisotropic BRDFs: We show (the interior components of ) derivatives obtained with and without our antithetic sampling technique using three base differentiable rendering methods: unidirectional path tracing with edge sampling (Edge) [Li et al. 2018], unidirectional path-space method (PS1) [Zhang et al. 2020]. Our technique allows significantly faster convergence for both base methods.",
      "Figure #": "8",
      "Link to Paper": "https://shuangz.com/projects/antithetic-sg21/antithetic-sg21.pdf",
      "Sub-field": "Rendering",
      "Title": "Antithetic Sampling for Monte Carlo Differentiable Rendering",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "calligrams": {
      "Authors": [
         "Changqing Zou",
         "Junjie Cao",
         "Warunika Ranaweera",
         "Ibraheem Alhashim",
         "Ping Tan",
         "Alla Sheffer",
         " Hao Zhang"
      ],
      "Caption": "A gallery of compact calligrams obtained by our method on input shapes obtained via Google image search.",
      "Figure #": "14",
      "Link to Paper": "https://www.cs.sfu.ca/~haoz/pubs/zou_sig16_calli.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Legible Compact Calligrams",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2016"
   },
   "diffusionhalftone": {
      "Authors": [
         "Alan Brunton",
         "Can Ates Arikan",
         "Philipp Urban"
      ],
      "Caption": "Traversal of a surface maintaining consistent orientation of an error diffusion filter. Left: a rendering of a 1 cm voxelization of a head model before and after halftoning. Middle: a close-up of the halftoning process up to a given slice. Right: a cut-out from the middle of how a 3-component filter moves as each voxel is quantized. Note: the halftone is shown as opaque and diffuse for illustration purposes, and does not reflect the printed appearance",
      "Figure #": "6",
      "Link to Paper": "https://arxiv.org/pdf/1506.02400.pdf",
      "Sub-field": "Fabrication",
      "Title": "Pushing the Limits of 3D Color Printing: Error Diffusion with Translucent Materials",
      "Type": "Logo",
      "Venue": "ToG",
      "Year": "2015"
   },
   "diffvec": {
      "Authors": [
         "Tzu-Mao Li",
         "Michal Luk\u00e1\u010d",
         "Micha\u00ebl Gharbi",
         "Jonathan Ragan-Kelley"
      ],
      "Caption": "Examples of our brush-based editing using image losses...(b) shows the result (below) of optimization of a block of text characters (above) to locally increase opacity according to a pixel stencil while preserving the shape of characters by optimizing text \"\u2018boldness\"\u2019.",
      "Figure #": "11",
      "Link to Paper": "https://people.csail.mit.edu/tzumao/diffvg/diffvg.pdf",
      "Sub-field": "Rendering",
      "Title": "Differentiable Vector Graphics Rasterization for Editing and Learning",
      "Type": "Logo",
      "Venue": "SIGGRAPH Asia",
      "Year": "2020"
   },
   "dronepaint": {
      "Authors": [
         "Valerii Serpiva",
         "Ekaterina Karmanova",
         "Aleksey Fedoseev",
         "Stepan Perminov",
         "Dzmitry Tsetserukou"
      ],
      "Caption": "a) View of user screen. Drawing trajectory by hand and gesture recognition. b) Long exposure light painting of \u201cSiggraph\u201d logo by drone. c) Single swarm agent with the LED circle.",
      "Figure #": "1",
      "Link to Paper": "https://dl.acm.org/doi/fullHtml/10.1145/3450550.3465349",
      "Sub-field": "Other",
      "Title": "DronePaint: Swarm Light Painting with DNN-based Gesture Recognition",
      "Type": "Name",
      "Venue": "SIGGRAPH (Emerging Technologies)",
      "Year": "2021"
   },
   "eikonal": {
      "Authors": [
         "Ivo Ihrke",
         "Gernot Ziegler",
         "Art Tevs",
         "Christian Theobalt",
         "Marcus Magnor",
         "Hans-Peter Seidel"
      ],
      "Caption": "Glass block with embedded SIGGRAPH logo of different refraction and attenuation, 15.5 fps, (5 objects in scene)",
      "Figure #": "8",
      "Link to Paper": "https://resources.mpi-inf.mpg.de/EikonalRendering/pdf/sig07.pdf",
      "Sub-field": "Rendering",
      "Title": "Eikonal Rendering: Efficient Light Transport in Refractive Objects",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2007"
   },
   "fabricformwork": {
      "Authors": [
         "Xiaoting Zhang",
         "Guoxin Fang",
         "Melina Skouras",
         "Gwenda Gieseler",
         "Charlie C.L. Wang",
         "Emily Whiting"
      ],
      "Caption": "Examples of optimized letter models. (Yellow) Optimized shape computed by our framework. (Blue) Deformed shape with unoptimized panels shown for comparison. (Multicolor) Design configuration with panels displayed in different colors and rotated according to fabrication orientation",
      "Figure #": "7",
      "Link to Paper": "https://cs-people.bu.edu/whiting/resources/pubs/Zhang2019_FabricFormwork.pdf",
      "Sub-field": "Fabrication",
      "Title": "Computational Design of Fabric Formwork",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2019"
   },
   "fermatspirals": {
      "Authors": [
         "Haisen Zhao",
         "Fanglin Gu",
         "Qixing Huang",
         "Jorge Garcia",
         "Yong Chen",
         "Changhe Tu",
         "Bedrich Benes",
         "Hao Zhang",
         "Daniel Cohen-Or",
         "Baoquan Chen"
      ],
      "Caption": "A gallery of continuous CFS tool paths generated by our algorithm. Shown as insets, the input shapes, both synthetic and from slices of fabricated 3D objects (see the honeycomb slices in last row as well as in Figure 1), exhibit varying degrees of complexity in terms of convexity/concavity of boundaries and hollowness.",
      "Figure #": "8",
      "Link to Paper": "https://www.cs.sfu.ca/~haoz/pubs/zhao_sig16_fermat.pdf",
      "Sub-field": "Fabrication",
      "Title": "Connected fermat spirals for layered fabrication",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2016"
   },
   "filamentplasma": {
      "Authors": [
         "Marcel Padilla",
         "Oliver Gross",
         "Felix Kn\u00f6ppel",
         "Albert Chern",
         "Ulrich Pinkall",
         "Peter Schr\u00f6der"
      ],
      "Caption": "An artistically designed flux map (botom) and the corresponding solar atmosphere (top). An animated version is provided in the supplementary material.",
      "Figure #": "2",
      "Link to Paper": "https://www3.math.tu-berlin.de/geometrie/wp_padilla/wp-content/uploads/2022/05/Filament_Based_Plasma.pdf",
      "Sub-field": "Simulation",
      "Title": "Filament Based Plasma",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2022"
   },
   "fluorescence": {
      "Authors": [
         "Jongho Lee",
         "Jenu Varghese Chacko",
         "Bing Dai",
         "Syed Azer Reza",
         "Abdul Kader Sagar",
         "Kevin W. Eliceiri",
         "Andreas Velten",
         "Mohit Gupta"
      ],
      "Caption": "Visual comparisons of fluorescence lifetime images. (a) Solid fluorescent samples with two lifetimes were made using the fluorescent tape (foreground) and the fluorescent slide (background). The fluorescence lifetime images were obtained by two coding schemes, (b) SinusoidSinusoid and (c) Expo-Square. The boundaries between the foreground and background are invisible with Sinusoid-Sinusoid but clear with ExpoSquare.",
      "Figure #": "16",
      "Link to Paper": "https://wisionlab.com/wp-content/uploads/2019/06/ToG19_FLIM_Jongho_Combined.pdf",
      "Sub-field": "Imaging/Video",
      "Title": "Coding Scheme Optimization for Fast Fluorescence Lifetime Imaging",
      "Type": "Logo",
      "Venue": "ToG",
      "Year": "2019"
   },
   "ganterrain": {
      "Authors": [
         "Eric Gu\u00e9rin",
         "Julie Digne",
         "Eric Galin",
         "Adrien Peytavie",
         "Christian Wolf",
         "Bedrich Benes",
         "Beno\u00eet Martinez "
      ],
      "Caption": "The iterative sketching can be used to generate complex shapes. Here the user sketches the Siggraph logo by adding a disk, carving a part of the levelset out, and finally adding details. This whole editing sequence is performed using the levelset-to-terrain synthesizer",
      "Figure #": "13",
      "Link to Paper": "https://hal.archives-ouvertes.fr/hal-01583706v3/document",
      "Sub-field": "Modeling/Geometry",
      "Title": "Interactive Example-Based Terrain Authoring with Conditional Generative Adversarial Networks",
      "Type": "Logo",
      "Venue": "SIGGRAPH Asia",
      "Year": "2017"
   },
   "gtangle": {
      "Authors": [
         "Christian Santoni",
         "Fabio Pellacini"
      ],
      "Caption": "An example tangle generated by our group grammars. Every letter is decorated by a different set of patterns, displaying the expressive power of our formal grammar. We generated this tangle by recursively combining, in a meaningful manner, our grouping, geometrical and decorative operators, all of which are well-defined on sets of arbitrary polygons with holes",
      "Figure #": "1",
      "Link to Paper": "https://pellacini.di.uniroma1.it/publications/gtangle16/gtangle16-paper.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "gTangle: a Grammar for the Procedural Generation of Tangle Patterns",
      "Type": "Name",
      "Venue": "SIGGRAPH Asia",
      "Year": "2016"
   },
   "kelvintransform": {
      "Authors": [
         "Mohammad Sina Nabizadeh",
         "Ravi Ramamoorthi",
         "Albert Chern"
      ],
      "Caption": "Cross field visualized on the exterior of the letters using Monte Carlo together with Kelvin transform. Blue and red points represent negative and positive singularities, respectively",
      "Figure #": "15",
      "Link to Paper": "https://cseweb.ucsd.edu/~viscomp/projects/SIG21KelvinTransform/paper/KelvinTransform.pdf",
      "Sub-field": "Simulation",
      "Title": "Kelvin Transformations for Simulations on Infinite Domains",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "laplaciangrowth": {
      "Authors": [
         "Theodore Kim",
         "Jason Sewall",
         "Avneesh Sud",
         "Ming Lin"
      ],
      "Caption": "b) 2D Fractal forms generated with our algorithm. The SIGGRAPH logo is a frame from a short animation featured in the SIGGRAPH 2005 Electronic Theater.",
      "Figure #": "5",
      "Link to Paper": "http://gamma.cs.unc.edu/FRAC/laplacian_large.pdf",
      "Sub-field": "Simulation",
      "Title": "Fast Simulation of Laplacian Growth",
      "Type": "Logo",
      "Venue": "Computer Graphics & Applications",
      "Year": "2007"
   },
   "logan": {
      "Authors": [
         "Kangxue Yin",
         "Zhiqin Chen",
         "Hui Huang",
         "Daniel Cohen-Or",
         "Hao Zhang"
      ],
      "Caption": "We present LOGAN, a deep neural network which learns general-purpose shape transforms from unpaired domains. By altering only the two input data domains for training, without changing the network architecture or any hyper-parameters, LOGAN can...learn both style-preserving content transfer (letters R \u2192 P, A \u2192 H, in different font styles) and content-preserving style transfer (wide to narrow S, thick to thin I, thin to thick G, and italic to non-italic A.) [Curator note: These letters are an anagram for...?]",
      "Figure #": "1",
      "Link to Paper": "https://arxiv.org/abs/1903.10170",
      "Sub-field": "Modeling/Geometry",
      "Title": "LOGAN: Unpaired Shape Transform in Latent Overcomplete Space",
      "Type": "Name",
      "Venue": "SIGGRAPH Asia",
      "Year": "2019"
   },
   "magneticflakes": {
      "Authors": [
         "Thiago Pereira",
         "Carolina L. A. Paes Leme",
         "Steve Marschner",
         "Szymon Rusinkiewicz"
      ],
      "Caption": "SIGGRAPH logo printed with the spiral field, lit at decreasing elevation angles. The background was created with a spiral that goes all the way to vertical, yielding a dark appearance. The logo itself is specular, created with the circular field.",
      "Figure #": "17",
      "Link to Paper": "https://gfx.cs.princeton.edu/pubs/Pereira_2017_PAA/flakes.pdf",
      "Sub-field": "Fabrication",
      "Title": "Printing Anisotropic Appearance with Magnetic Flakes",
      "Type": "Logo",
      "Venue": "ToG",
      "Year": "2017"
   },
   "magnetoelastic": {
      "Authors": [
         "Xuwen Chen",
         "Xingyu Ni",
         "Bo Zhu",
         "Bin Wang",
         "Baoquan Chen"
      ],
      "Caption": "SIGGRAPH banner. The eight letters are individually optimized as in the right of Figure 9b, and then their optimized material properties are assembled to form the banner.",
      "Figure #": "8",
      "Link to Paper": "https://dl.acm.org/doi/abs/10.1145/3528223.3530142",
      "Sub-field": "Simulation",
      "Title": "Simulation and optimization of magnetoelastic thin shells",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2022"
   },
   "manyworlds": {
      "Authors": [
         "Christopher D. Twigg",
         "Doug L. James"
      ],
      "Caption": "Spelling SIGGRAPH: Using our parallel refinement with spatial queries and metrics enables a user to generate this animation spelling out \u201cSIGGRAPH\u201d from an arbitrarily chosen starting configuration.",
      "Figure #": "1",
      "Link to Paper": "http://graphics.cs.cmu.edu/projects/mwb/manyWorldsBrowsing.pdf",
      "Sub-field": "Simulation",
      "Title": "Many-Worlds Browsing for Control of Multibody Dynamics",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2007"
   },
   "markerlessgarments": {
      "Authors": [
         "Derek Bradley",
         "Tiberiu Popa",
         "Alla Sheffer",
         "Wolfgang Heidrich",
         "Tamy Boubekeur"
      ],
      "Caption": "Left to right: an actor performing in the capture setup; one of sixteen views from the camera array; reconstructed T-shirt geometry; the real T-shirt is replaced by a rendering of the captured geometry with different appearance characteristics.",
      "Figure #": "1",
      "Link to Paper": "http://www.cs.ubc.ca/labs/imager/tr/2008/MarkerlessGarmentCapture/",
      "Sub-field": "Modeling/Geometry",
      "Title": "Markerless Garment Capture",
      "Type": "Both",
      "Venue": "SIGGRAPH",
      "Year": "2008"
   },
   "metropolispm_1": {
      "Authors": [
         "Jerry O. Talton",
         "Yu Lou",
         "Jared Duke",
         "Steve Lesser",
         "Radomir Mech",
         "Vladlen Koltun"
      ],
      "Caption": "A set of young oak trees from a single grammar, produced with the algorithm described in this paper. The trees exhibit natural, realistic structure (top) and spell \u201cSIGGRAPH\u201d when viewed from above (bottom). Zoom in for detail",
      "Figure #": "8",
      "Link to Paper": "http://vladlen.info/papers/metropolis.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Metropolis Procedural Modeling",
      "Type": "Name",
      "Venue": "ToG",
      "Year": "2011"
   },
   "metropolispm_2": {
      "Authors": [
         "Jerry O. Talton",
         "Yu Lou",
         "Jared Duke",
         "Steve Lesser",
         "Radomir Mech",
         "Vladlen Koltun"
      ],
      "Caption": "Acacia trees (left) and willows (right) targeted to the SIGGRAPH logo. Zoom in to see the small branches supporting the thin edges of the crescent shapes",
      "Figure #": "9",
      "Link to Paper": "http://vladlen.info/papers/metropolis.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Metropolis Procedural Modeling",
      "Type": "Logo",
      "Venue": "ToG",
      "Year": "2011"
   },
   "minkowski": {
      "Authors": [
         "Ji\u0159\u00ed Minar\u010d\u00edk",
         "Sam Estep",
         "Wode Ni",
         "Keenan Crane"
      ],
      "Caption": "Minkowski penalties provide robust enforcement of general geometric predicates, for a wide variety of shapes. Here we highlight, from left to right: (S) glyph placement with precise padding, (I) nested containment, (GG) successful optimization from a highly infeasible state, (R) high-quality packing and boundary alignment, (A) joint constraint enforcement and energy optimization, (P) constraint enforcement for shapes that do not have a well-defined inside/outside, and (H) no-overlap constraints integrated with graph layout. In each case (except (I)), shapes are confined to a nonconvex region.",
      "Figure #": "1",
      "Link to Paper": "https://www.cs.cmu.edu/~woden/assets/siggraph-24-minkowski.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Minkowski Penalties: Robust Differentiable Constraint Enforcement for Vector Graphics",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2024"
   },
   "multireflectors": {
      "Authors": [
         "Kaisei Sakurai",
         "Yoshinori Dobashi",
         "Kei Iwasaki",
         "Tomoyuki Nishita"
      ],
      "Caption": "Color changing effect. Photographs of the fabricated reflector displaying the SIGGRAPH logo with four different color variations. The input images are shown in the inset",
      "Figure #": "6",
      "Link to Paper": "http://ksakurai.sakura.ne.jp/SG18/SG18_pv/fabricating_reflector_sig2018_fin2.pdf",
      "Sub-field": "Fabrication",
      "Title": "Fabricating Reflectors for Displaying Multiple Images",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2018"
   },
   "onenoise": {
      "Authors": [
         "Arman Maesumi",
         "Dylan Hu",
         "Krishi Saripalli",
         "Vladimir G. Kim",
         "Matthew Fisher",
         "S\u00f6ren Pirk",
         "Daniel Ritchie"
      ],
      "Caption": "Our method enables the synthesis of a wide range of noise patterns with spatially-varying characteristics. Here we show the flexibility of our unified noise model, allowing one to art-direct their noise in a granular fashion. Our model creates semantically meaningful interpolations between noise configurations; above we see the Siggraph logo written with hay fibers that are nested inside of Damascus steel striations\u2013 the scale and distortion of the steel pattern naturally interpolates into a denser pattern before transitioning into fibers. We also show renderings of a clay shader that incorporates our spatially-varying noise patterns. The first three images make use of class-interpolated noise, the final image uses parameter-interpolated noise. Please zoom into the figures for full visual detail.",
      "Figure #": "1",
      "Link to Paper": "https://armanmaesumi.github.io/onenoise/",
      "Sub-field": "Imaging/Video",
      "Title": "One Noise to Rule Them All: Learning a Unified Model of Spatially-Varying Noise Patterns",
      "Type": "Both",
      "Venue": "SIGGRAPH",
      "Year": "2024"
   },
   "pathreplaybp": {
      "Authors": [
         "Delio Vicini",
         "S\u00e9bastien Speierer",
         "Wenzel Jakob"
      ],
      "Caption": "We optimize the normal map of a glass slab so that the refracted view matches a reference image. Neither biased nor unbiased radiative backpropagation can optimize a perfectly specular surface, hence we compare our method to conventional automatic differentiation (at equal iteration count).",
      "Figure #": "10",
      "Link to Paper": "http://rgl.s3.eu-central-1.amazonaws.com/media/papers/Vicini2021PathReplay_2.pdf",
      "Sub-field": "Rendering",
      "Title": "Path Replay Backpropagation: Differentiating Light Paths using Constant Memory and Linear Time",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "phasornoise": {
      "Authors": [
         "Thibault Tricard",
         "Semyon Efremov",
         "C\u00e9dric Zanni",
         "Fabrice Neyret",
         "Jon\u00e0s Mart\u00ednez",
         "Sylvain Lefebvre "
      ],
      "Caption": "Columns, from left to right: Control fields, frequency control, PWM \u2018width\u2019 control, orientation control, all together",
      "Figure #": "15",
      "Link to Paper": "https://hal.archives-ouvertes.fr/hal-02118508/document",
      "Sub-field": "Other",
      "Title": "Procedural Phasor Noise",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2019"
   },
   "poissoncaustics": {
      "Authors": [
         "Yonghao Yue",
         "Kei Iwasaki",
         "Bing-Yu Chen",
         "Yoshinori Dobashi",
         "Tomoyuki Nishita"
      ],
      "Caption": "From left to right: photographs of the fabricated objects and their caustics, the simulated caustic patterns, and the caustic patterns of the fabricated objects.",
      "Figure #": "11",
      "Link to Paper": "http://nishitalab.org/user/egaku/tog14/yue-continuous-caustics-lens.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Poisson-Based Continuous Surface Generation for Goal-Based Caustics",
      "Type": "Logo",
      "Venue": "ToG",
      "Year": "2014"
   },
   "qrcodes": {
      "Authors": [
         "Hung-Kuo Chu",
         "Chia-Sheng Chang",
         "Ruen-Rone Lee",
         "Niloy J. Mitra"
      ],
      "Caption": "By using a new representation model that minimally binds to the appearance of QR code, our approach is able to combine halftone images with ordinary QR codes without compromising its readability.",
      "Figure #": "1",
      "Link to Paper": "https://cgv.cs.nthu.edu.tw/download/file?guid=a3f1b3da-4b13-11e5-846f-00113247b9b2",
      "Sub-field": "Imaging/Video",
      "Title": "Halftone QR Codes",
      "Type": "Logo",
      "Venue": "SIGGRAPH Asia",
      "Year": "2013"
   },
   "saliencysummary": {
      "Authors": [
         "Radhakrishna Achanta",
         "Appu Shaji",
         "Pascal Fua",
         "Sabine S\u00fcsstrunk"
      ],
      "Caption": "Database saliency automatically finds the most salient images from thousands of images for creating interesting mosaics (eg. A and B) or collages (eg. C and D).",
      "Figure #": "1",
      "Link to Paper": "https://www.epfl.ch/labs/ivrl/research/saliency/database-saliency-and-image-summaries/",
      "Sub-field": "Imaging/Video",
      "Title": "Image Summaries using Database Saliency",
      "Type": "Logo",
      "Venue": "SIGGRAPH Asia (Posters)",
      "Year": "2009"
   },
   "shadowart": {
      "Authors": [
         "Niloy J. Mitra",
         "Mark Pauly"
      ],
      "Caption": "Example-based shadow art. Well-known graphics models are used to create a constructive shadow art sculpture that casts three shadows at 45 degree angle depicting the Siggraph logo.",
      "Figure #": "8",
      "Link to Paper": "https://graphics.stanford.edu/~niloy/research/shadowArt/paper_docs/shadowArt_sigA_09.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Shadow Art",
      "Type": "Logo",
      "Venue": "SIGGRAPH Asia",
      "Year": "2009"
   },
   "sosmc": {
      "Authors": [
         "Daniel Ritchie",
         "Ben Mildenhall",
         "Noah D. Goodman",
         "Pat Hanrahan"
      ],
      "Caption": "Using the object avoidance scoring function to make gnarly trees grow around obstacles.",
      "Figure #": "4",
      "Link to Paper": "https://dritchie.github.io/pdf/sosmc.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Controlling Procedural Modeling Programs with Stochastically-Ordered Sequential Monte Carlo",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2015"
   },
   "specklestats": {
      "Authors": [
         "Chen Bar",
         "Marina Alterman",
         "Ioannis Gkioulekas",
         "Anat Levin"
      ],
      "Caption": "Replication of a seeing through scattering layer application of (Katz et al. 2014). A set of illuminators with the arrangement at the top of (a) generates a semi-random speckle image, yet the auto-correlation of the speckle image is similar to the auto-correlation of the original illuminators and hence the illuminators can be recovered from the speckle image using phase retrieval algorithms. In (b,c) we show the auto-correlation and the corresponding reconstruction for different material parameters simulated with our speckle renderer. The success of the algorithm depends on the validity of the memory effect in this angular range for each type of material.",
      "Figure #": "12",
      "Link to Paper": "https://arxiv.org/pdf/1901.06931.pdf",
      "Sub-field": "Rendering",
      "Title": "A Monte Carlo Framework for Rendering Speckle Statistics in Scattering Media",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2019"
   },
   "sweptvolumes": {
      "Authors": [
         "Silvia Sellan",
         "Noam Aigerman",
         "Alec Jacobson"
      ],
      "Caption": "We capture trajectories with a real VR setup and then sweep different letters\u2019 mesh representations along them.",
      "Figure #": "16",
      "Link to Paper": "https://www.dgp.toronto.edu/projects/swept-volumes/swept-volumes-low-res.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "Swept Volumes via Spacetime Numerical Continuation",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "teg": {
      "Authors": [
         "Sai Bangaru",
         "Jesse Michel",
         "Kevin Mu",
         "Gilbert Bernstein",
         "Tzu-Mao Li",
         " Jonathan Ragan-Kelley"
      ],
      "Caption": "Guided Perlin textures. We optimize for the parameters of two shaders based on Perlin noise. The shader in (a) uses the Perlin noise value to decide between using a flat gray color and a low-resolution color map. We keep the decision threshold value fixed and optimize for the color map as well as the noise vectors of the Perlin grid. Ignoring the delta contribution leads to an unchanged noise pattern, while our approach produces a noise pattern that adhere to the logo structure. ",
      "Figure #": "9",
      "Link to Paper": "https://people.csail.mit.edu/sbangaru/projects/teg-2021/teg-2021.pdf",
      "Sub-field": "Other",
      "Title": "Systematically Differentiating Parametric Discontinuities",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "terafoils": {
      "Authors": [
         "Kenta Yamamoto",
         "Kosaku Namikawa",
         "Yoichi Ochiai"
      ],
      "Caption": "Left: holographic tag card of TeraFoils. Center: experimental setup with sub-terahertz detector array and subterahertz source. Right: hologram generated by the proposed method, simulated result, and captured result (SIGGRAPH logo).",
      "Figure #": "1",
      "Link to Paper": "https://digitalnature.slis.tsukuba.ac.jp/wp-content/uploads/2021/07/2021_SIGGRAPH_Posters_TeraFoils-15.pdf",
      "Sub-field": "Fabrication",
      "Title": "TeraFoils: Design and Rapid Fabrication Techniques for Binary Holographic Structures in the Terahertz Region",
      "Type": "Logo",
      "Venue": "SIGGRAPH (Posters)",
      "Year": "2021"
   },
   "tilingnn": {
      "Authors": [
         "Hao Xu",
         "Ka-Hei Hui",
         "Chi-Wing Fu",
         "Hao Zhang"
      ],
      "Caption": "Our self-supervised neural network, TilinGNN, produces tiling results in time roughly linear to the number of candidate tile locations, significantly outperforming traditional combinatorial search methods. The average runtime of our network for tiling a character is only 25.71s. The character shapes to be tiled are shown in grey and different types of tiles are displayed using different colors (note that mirror reflections count as different tile types)",
      "Figure #": "1",
      "Link to Paper": "https://xuhaocuhk.github.io/projects/TilinGnn/xu-2020-TilinGnn.pdf",
      "Sub-field": "Modeling/Geometry",
      "Title": "TilinGNN: Learning to Tile with Self-Supervised Graph Neural Network",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2020"
   },
   "vertexmerging": {
      "Authors": [
         "Iliyan Georgiev",
         "Jaroslav K\u0159iv\u00e1nek",
         "Philipp Slusallek"
      ],
      "Caption": "Left: The SIGGRAPH Souvenirs scene reference image. Middle: insets showing the quality achieved by 4 different algorithms in the same time (200 seconds): Combined vertex merging with bidirectional path tracing (VM+BDPT), vertex merging only (VM), progressive photon mapping (PPM), bidrectional path tracing (BDPT). The new VM+BDPT algorithm combines various path sampling techniques to produce the image with the lowest overall error. Right: a path segment generated by a vertex connection (top) and by vertex merging (bottom).",
      "Figure #": "1",
      "Link to Paper": "https://iliyan.com/publications/VertexMergingSketch",
      "Sub-field": "Rendering",
      "Title": "Bidirectional light transport with vertex merging",
      "Type": "Both",
      "Venue": "SIGGRAPH Asia Technical Sketches",
      "Year": "2011"
   },
   "viscoelasticmpm_1": {
      "Authors": [
         "Haozhe Su",
         "Tao Xue",
         "Chengguizi Han",
         "Chenfanfu Jiang",
         "Mridul Aanjaneya"
      ],
      "Caption": "Our unified constitutive model can simulate both Newtonian and non-Newtonian viscous liquids[, including] object interaction with Newtonian ketchup bunnies.",
      "Figure #": "1",
      "Link to Paper": "https://rutgers.box.com/shared/static/8urdpsy1czgtqe6irc9gq53uhgfodf6x.pdf",
      "Sub-field": "Simulation",
      "Title": "A Unified Second-Order Accurate in Time MPM Formulation for Simulating Viscoelastic Liquids with Phase Change",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "viscoelasticmpm_2": {
      "Authors": [
         "Haozhe Su",
         "Tao Xue",
         "Chengguizi Han",
         "Chenfanfu Jiang",
         "Mridul Aanjaneya"
      ],
      "Caption": "Our unified constitutive model can simulate both Newtonian and non-Newtonian viscous liquids[, including] 3D printing of shapes.",
      "Figure #": "1",
      "Link to Paper": "https://rutgers.box.com/shared/static/8urdpsy1czgtqe6irc9gq53uhgfodf6x.pdf",
      "Sub-field": "Simulation",
      "Title": "A Unified Second-Order Accurate in Time MPM Formulation for Simulating Viscoelastic Liquids with Phase Change",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "viscoelasticmpm_3": {
      "Authors": [
         "Haozhe Su",
         "Tao Xue",
         "Chengguizi Han",
         "Chenfanfu Jiang",
         "Mridul Aanjaneya"
      ],
      "Caption": "(Top) The individual letters of SIGGRAPH were 3D printed (in simulation) using our method that provides a unified framework for thermo-viscoelastic effects. (Bottom) The letters deform differently when dropped on the printer bed, illustrating that the material stiffness depends on the fabrication process. The average delta t during simulations is 6 \u00d7 10\u22125s.",
      "Figure #": "16",
      "Link to Paper": "https://rutgers.box.com/shared/static/8urdpsy1czgtqe6irc9gq53uhgfodf6x.pdf",
      "Sub-field": "Simulation",
      "Title": "A Unified Second-Order Accurate in Time MPM Formulation for Simulating Viscoelastic Liquids with Phase Change",
      "Type": "Name",
      "Venue": "SIGGRAPH",
      "Year": "2021"
   },
   "voronoifoams": {
      "Authors": [
         "Jon\u00e0s Mart\u00ednez",
         "J\u00e9r\u00e9mie Dumas",
         "Sylvain Lefebvre"
      ],
      "Caption": "SIGGRAPH logo driving the density field.",
      "Figure #": "16",
      "Link to Paper": "https://sites.google.com/site/jonasmartinezbayona/procvorfoam",
      "Sub-field": "Fabrication",
      "Title": "Procedural Voronoi Foams for Additive Manufacturing",
      "Type": "Logo",
      "Venue": "SIGGRAPH",
      "Year": "2016"
   },
   "weavecraft": {
      "Authors": [
         "Rundong Wu",
         "Joy Xiaoji Zhang",
         "Jonathan Leaf",
         "Xinru Hua",
         "Ante Qu",
         "Claire Harvey",
         "Emily Holtzman",
         "Joy Ko",
         "Brooks Hagan",
         "Doug James",
         "Fran\u00e7ois Guimbreti\u00e8re",
         "Steve Marschner"
      ],
      "Caption": "Illustration of stenciling. To merge several blocks with a stencil, we first tile every block respectively so that the x and y sizes of the tiled blocks are no smaller than the stencil. Then for each pixel in the stencil, we grab a stack from the corresponding tiled block according to the index value. The merged block is a combination of these stacks.",
      "Figure #": "8",
      "Link to Paper": "https://www.cs.cornell.edu/~joyxiaojizhang/files/weavecraft.pdf",
      "Sub-field": "Fabrication",
      "Title": "Weavecraft: An Interactive Design and Simulation Tool for 3D Weaving",
      "Type": "Logo",
      "Venue": "SIGGRAPH Asia",
      "Year": "2020"
   },
   "wireart": {
      "Authors": [
         "Kai-Wen Hsiao",
         "Jia-Bin Huang",
         "Hung-Kuo Chu"
      ],
      "Caption": "We present an algorithm that takes line drawing images and the spatial arrangement of viewpoints as inputs and produces 3D wire sculpture art showing distinct interpretations when viewed at different angles...The 3D wire art can be appreciated either with light sources casting shadows onto external planar surfaces or directly viewing from certain viewpoints",
      "Figure #": "1",
      "Link to Paper": "https://cgv.cs.nthu.edu.tw/download/file?guid=3d4d4ee9-cdec-11e8-9b71-0011328fa92e",
      "Sub-field": "Modeling/Geometry",
      "Title": "Multi-view Wire Art",
      "Type": "Both",
      "Venue": "SIGGRAPH Asia",
      "Year": "2018"
   }
}